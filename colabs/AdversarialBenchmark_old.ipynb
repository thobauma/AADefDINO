{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVYi_Zwu91it"
   },
   "source": [
    "# Install, Paths and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194352,
     "status": "ok",
     "timestamp": 1639413378140,
     "user": {
      "displayName": "Javier Rando",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06593485543899718786"
     },
     "user_tz": -60
    },
    "id": "H3qhJR_04HNn",
    "outputId": "6481d784-89a8-4bdc-e0f9-345af6b3d7ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.7.1\n",
      "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 776.8 MB 16 kB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.19.5)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.0+cu111\n",
      "    Uninstalling torch-1.10.0+cu111:\n",
      "      Successfully uninstalled torch-1.10.0+cu111\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
      "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
      "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.7.1\n",
      "Collecting torchvision==0.8.2\n",
      "  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 5.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (7.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (1.19.5)\n",
      "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (1.7.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->torchvision==0.8.2) (3.10.0.2)\n",
      "Installing collected packages: torchvision\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.11.1+cu111\n",
      "    Uninstalling torchvision-0.11.1+cu111:\n",
      "      Successfully uninstalled torchvision-0.11.1+cu111\n",
      "Successfully installed torchvision-0.8.2\n",
      "Collecting torchattacks\n",
      "  Downloading torchattacks-3.2.3-py3-none-any.whl (102 kB)\n",
      "\u001b[K     |████████████████████████████████| 102 kB 3.9 MB/s \n",
      "\u001b[?25hInstalling collected packages: torchattacks\n",
      "Successfully installed torchattacks-3.2.3\n"
     ]
    }
   ],
   "source": [
    "# Requirements. Need to restart after installation (it sucks, I am sorry haha)\n",
    "!pip install torch==1.7.1\n",
    "!pip install torchvision==0.8.2\n",
    "!pip install torchattacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5283,
     "status": "ok",
     "timestamp": 1639416078104,
     "user": {
      "displayName": "Javier Rando",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06593485543899718786"
     },
     "user_tz": -60
    },
    "id": "wMiKhBahg23V",
    "outputId": "8e6e2d4e-f81e-4d7e-8747-0a0494bad44c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1639416078511,
     "user": {
      "displayName": "Javier Rando",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06593485543899718786"
     },
     "user_tz": -60
    },
    "id": "RDBcKRbJYciA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from typing import List, Callable\n",
    "import random\n",
    "\n",
    "# seed\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1639416078512,
     "user": {
      "displayName": "Javier Rando",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06593485543899718786"
     },
     "user_tz": -60
    },
    "id": "Jz2fe6PfYh_0"
   },
   "outputs": [],
   "source": [
    "# general path\n",
    "DRIVE_PATH = '/content/drive/MyDrive/'\n",
    "DL_PROJECT_PATH = os.path.join(DRIVE_PATH, 'DeepLearningProject')\n",
    "ADV_PATH = os.path.join(DL_PROJECT_PATH, 'AdversarialAttacks')\n",
    "\n",
    "# filenames and label path\n",
    "ORG_LABEL_PATH = os.path.join(ADV_PATH,'ori_data/correct_labels_cl.txt')\n",
    "\n",
    "# image paths\n",
    "ORIGINAL_IMAGES_PATH = os.path.join(ADV_PATH,'ori_data/ImageNetClasses/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1639416078513,
     "user": {
      "displayName": "Javier Rando",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06593485543899718786"
     },
     "user_tz": -60
    },
    "id": "yP4i522l-m7o"
   },
   "outputs": [],
   "source": [
    "def get_random_classes(number_of_classes: int = 50, min_rand_class: int = 0, max_rand_class: int = 999):\n",
    "  return np.random.randint(low=min_rand_class, high=max_rand_class, size=(number_of_classes,))\n",
    "\n",
    "def get_random_indexes(number_of_images: int = 50000, n_samples=1000):\n",
    "  return np.random.choice(50000, 1000, replace=False)\n",
    "\n",
    "INDEX_SUBSET = get_random_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6wDjrMNFIQO"
   },
   "source": [
    "# Import DINO\n",
    "Official repo: https://github.com/facebookresearch/dino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2617,
     "status": "ok",
     "timestamp": 1639416081124,
     "user": {
      "displayName": "Javier Rando",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06593485543899718786"
     },
     "user_tz": -60
    },
    "id": "F14gzRs4vaU9",
    "outputId": "fff19bf4-5482-4459-f1e3-48a222a0978f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained weights from PyTorch\n",
    "device = 'cuda'\n",
    "vits16 = torch.hub.load('facebookresearch/dino:main', 'dino_vits8').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1639416081125,
     "user": {
      "displayName": "Javier Rando",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06593485543899718786"
     },
     "user_tz": -60
    },
    "id": "9TRurWCDFsr3"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "N_LAST_BLOCKS = 4 # Took from official repo\n",
    "PATCH_SIZE=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1639416081126,
     "user": {
      "displayName": "Javier Rando",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06593485543899718786"
     },
     "user_tz": -60
    },
    "id": "7mNTPKGX1AOY",
    "outputId": "b907414b-09b1-4088-c1ff-92e14c13146c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and load pretrained weights for linear classifier on ImageNet\n",
    "from torch import nn\n",
    "class LinearClassifier(nn.Module):\n",
    "    \"\"\"Linear layer to train on top of frozen features\"\"\"\n",
    "    def __init__(self, dim, num_labels=1000):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.linear = nn.Linear(dim, num_labels) \n",
    "        self.linear.weight.data.normal_(mean=0.0, std=0.01)\n",
    "        self.linear.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # linear layer\n",
    "        return self.linear(x)\n",
    "\n",
    "linear_classifier = LinearClassifier(vits16.embed_dim * N_LAST_BLOCKS, num_labels=1000)\n",
    "linear_classifier = linear_classifier.cuda()\n",
    "\n",
    "linear_state_dict = torch.hub.load_state_dict_from_url(url=\"https://dl.fbaipublicfiles.com/dino/\" + \"dino_deitsmall8_pretrain/dino_deitsmall8_linearweights.pth\")[\"state_dict\"]\n",
    "\n",
    "# Update state dict to avoid crash. Workaround.\n",
    "linear_state_dict['linear.weight'] = linear_state_dict.pop('module.linear.weight')\n",
    "linear_state_dict['linear.bias'] = linear_state_dict.pop('module.linear.bias')\n",
    "\n",
    "# Load pre-trained weights\n",
    "linear_classifier.load_state_dict(linear_state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoZjtdI3HGQU"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1639416081126,
     "user": {
      "displayName": "Javier Rando",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06593485543899718786"
     },
     "user_tz": -60
    },
    "id": "zuyk3ebWU-Cc"
   },
   "outputs": [],
   "source": [
    "# Custom loader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "import traceback\n",
    "from PIL import Image\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "  def __init__(self, img_folder: str, file_name: str, transform: callable, class_subset: List[int] = None, index_subset: List[int] = None):\n",
    "    super().__init__()\n",
    "    self.transform=transform\n",
    "    self.img_folder=img_folder\n",
    "    self.data = self.create_df(file_name)\n",
    "    self.class_subset = class_subset\n",
    "    if self.class_subset is None:\n",
    "      if index_subset is not None:\n",
    "          self.data_subset = self.data.iloc[index_subset]\n",
    "      else:\n",
    "        self.data_subset = self.data\n",
    "    else:\n",
    "      self.data_subset = self.data[self.data['label'].isin(self.class_subset)] \n",
    "  \n",
    "  def create_df(self, file_name: str):\n",
    "    df = pd.read_csv(file_name, sep=\" \", header=None)\n",
    "    df.columns=['file', 'label']\n",
    "    return df\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.data_subset)\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    img = Image.open(os.path.join(self.img_folder,self.data_subset['file'].iloc[index]))\n",
    "    img = img.convert('RGB')\n",
    "\n",
    "    img=self.transform(img)\n",
    "    target=self.data_subset['label'].iloc[index]\n",
    "\n",
    "    return img,target,self.data_subset['file'].iloc[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1639416081127,
     "user": {
      "displayName": "Javier Rando",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06593485543899718786"
     },
     "user_tz": -60
    },
    "id": "4AqLkfGWj8f1"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms as pth_transforms\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Create loader\n",
    "# Taken from official repo: https://github.com/facebookresearch/dino/blob/main/eval_linear.py\n",
    "loader_transform = pth_transforms.Compose([\n",
    "    pth_transforms.Resize(256, interpolation=3),\n",
    "    pth_transforms.CenterCrop(224),\n",
    "    pth_transforms.ToTensor()\n",
    "])\n",
    "\n",
    "org_dataset = ImageDataset(img_folder = ORIGINAL_IMAGES_PATH,\n",
    "                           file_name = ORG_LABEL_PATH,\n",
    "                           transform=loader_transform,\n",
    "                           index_subset=INDEX_SUBSET)\n",
    "\n",
    "org_loader = torch.utils.data.DataLoader(\n",
    "    org_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1639416081127,
     "user": {
      "displayName": "Javier Rando",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06593485543899718786"
     },
     "user_tz": -60
    },
    "id": "2kETL113vduT",
    "outputId": "e1193c95-3ea5-476c-cf5a-79feea6fd101"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1639416081128,
     "user": {
      "displayName": "Javier Rando",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06593485543899718786"
     },
     "user_tz": -60
    },
    "id": "scekPa9ur6bX"
   },
   "outputs": [],
   "source": [
    "class ViTModel(torch.nn.Module):\n",
    "    def __init__(self, vits16, linear_layer):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(ViTModel, self).__init__()\n",
    "        self.vits16=vits16\n",
    "        self.linear_layer=linear_layer\n",
    "        self.transform = transform = pth_transforms.Compose([\n",
    "            pth_transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ])\n",
    "        \n",
    "        self.vits16.eval()\n",
    "        self.linear_layer.eval()\n",
    "\n",
    "    def forward(self, x, grad=True):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        if grad is False:\n",
    "          with torch.no_grad():\n",
    "            x = self.transform(x)\n",
    "            \n",
    "            # forward\n",
    "            intermediate_output = self.vits16.get_intermediate_layers(x, 4)\n",
    "            output = torch.cat([x[:, 0] for x in intermediate_output], dim=-1)\n",
    "            output = linear_classifier(output)\n",
    "            return output\n",
    "        else:\n",
    "          x = self.transform(x)\n",
    "            \n",
    "          # forward\n",
    "          intermediate_output = self.vits16.get_intermediate_layers(x, 4)\n",
    "          output = torch.cat([x[:, 0] for x in intermediate_output], dim=-1)\n",
    "          output = linear_classifier(output)\n",
    "          return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1639416081128,
     "user": {
      "displayName": "Javier Rando",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06593485543899718786"
     },
     "user_tz": -60
    },
    "id": "EcjYgFPZr8kI"
   },
   "outputs": [],
   "source": [
    "model = ViTModel(vits16, linear_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAFKqXULsBrx"
   },
   "source": [
    "# Attack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1639416557111,
     "user": {
      "displayName": "Javier Rando",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06593485543899718786"
     },
     "user_tz": -60
    },
    "id": "6mavCwpgr-tP"
   },
   "outputs": [],
   "source": [
    "import torchattacks\n",
    "from torchattacks import *\n",
    "\n",
    "attacks = [\n",
    "    FGSM(model, eps=0.062),\n",
    "    CW(model, c=50, lr=0.00155, steps=30)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2153195,
     "status": "ok",
     "timestamp": 1639418711540,
     "user": {
      "displayName": "Javier Rando",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06593485543899718786"
     },
     "user_tz": -60
    },
    "id": "_WfIlXeIsEdJ",
    "outputId": "7b877b09-d65e-477d-b94a-11c131304439"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "FGSM(model_name=ViTModel, device=cuda:0, eps=0.062, attack_mode=default, return_type=float)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [04:02<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time (sec): 1.98\n",
      "Accuracy against attack: 1.10 %\n",
      "Clean accuracy: 79.10 %\n",
      "----------------------------------------------------------------------\n",
      "CW(model_name=ViTModel, device=cuda:0, c=50, kappa=0, steps=30, lr=0.00155, attack_mode=default, return_type=float)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [31:50<00:00, 15.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time (sec): 12.15\n",
      "Accuracy against attack: 0.00 %\n",
      "Clean accuracy: 79.10 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for atk in attacks :\n",
    "    \n",
    "    print(\"-\"*70)\n",
    "    print(atk)\n",
    "    \n",
    "    correct = 0\n",
    "    clean_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels, _ in tqdm.tqdm(org_loader):\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        cuda_images = images.to(device)\n",
    "        clean_outputs = model(cuda_images, False)\n",
    "        del cuda_images\n",
    "\n",
    "        adv_images = atk(images, labels)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(adv_images)\n",
    "\n",
    "        _, pre = torch.max(outputs.data, 1)\n",
    "        _, pre_clean = torch.max(clean_outputs.data, 1)\n",
    "\n",
    "        total += len(labels.flatten())\n",
    "        correct += (pre == labels).sum()\n",
    "        clean_correct += (pre_clean == labels).sum()\n",
    "\n",
    "        del images\n",
    "        del labels\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print('Total elapsed time (sec): %.2f' % (time.time() - start))\n",
    "    print('Accuracy against attack: %.2f %%' % (100 * float(correct) / total))\n",
    "    print('Clean accuracy: %.2f %%' % (100 * float(clean_correct) / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FDoS3sI0S0S"
   },
   "source": [
    "#### Outputs\n",
    "* Clean accuracy: 79.10%\n",
    "* FGWS accuracy: 1.10%\n",
    "* CW accuracy: 0.00%"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AdversarialBenchmark.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
