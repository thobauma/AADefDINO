{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install, Paths and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import getpass\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# allow imports when running script from within project dir\n",
    "[sys.path.append(i) for i in ['.', '..']]\n",
    "\n",
    "# local\n",
    "from src.helpers.helpers import get_random_indexes, get_random_classes\n",
    "from src.model.dino_model import get_dino, ViTWrapper\n",
    "from src.model.data import create_loader\n",
    "\n",
    "# Custom imports\n",
    "import torchattacks\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchattacks import *\n",
    "import torch.optim as optim\n",
    "\n",
    "# seed\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "username = getpass.getuser()\n",
    "DATA_PATH = Path('/','cluster', 'scratch', 'thobauma', 'dl_data')\n",
    "LOG_PATH = Path(DATA_PATH, 'logs')\n",
    "\n",
    "ORI_PATH = Path(DATA_PATH, 'ori_data', 'validation')\n",
    "ORI_LABEL_PATH = Path(ORI_PATH,'correct_labels.txt')\n",
    "ORI_IMAGES_PATH = Path(ORI_PATH,'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_SUBSET = get_random_classes()\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python ../setup/collect_env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import DINO\n",
    "Official repo: https://github.com/facebookresearch/dino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please use the `--pretrained_weights` argument to indicate the path of the checkpoint to evaluate.\n",
      "Since no pretrained weights have been provided, we load the reference pretrained DINO weights.\n",
      "Model vit_small built.\n",
      "Embed dim 1536\n",
      "We load the reference pretrained linear weights.\n"
     ]
    }
   ],
   "source": [
    "model, base_linear_classifier = get_dino()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_loader = create_loader(ORI_IMAGES_PATH, ORI_LABEL_PATH, None, CLASS_SUBSET, BATCH_SIZE, is_adv_training=True)\n",
    "test_loader = ori_loader # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a custom linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and load pretrained weights for linear classifier on ImageNet\n",
    "from torch import nn\n",
    "class LinearClassifier(nn.Module):\n",
    "    \"\"\"Linear layer to train on top of frozen features\"\"\"\n",
    "    def __init__(self, dim, num_labels=1000, hidden_size=512):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.linear = nn.Linear(dim, hidden_size) \n",
    "        self.linear2 = nn.Linear(hidden_size, num_labels) \n",
    "        self.linear.weight.data.normal_(mean=0.0, std=0.01)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear2.weight.data.normal_(mean=0.0, std=0.01)\n",
    "        self.linear2.bias.data.zero_()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # linear layer\n",
    "        x = self.relu(self.linear(x))\n",
    "        return self.linear2(x)\n",
    "\n",
    "linear_classifier = LinearClassifier(base_linear_classifier.linear.in_features, num_labels=len(CLASS_SUBSET))\n",
    "linear_classifier = linear_classifier.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create custom Torch wrapper for the model so that it can be passsed to the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = ViTWrapper(model, linear_classifier)\n",
    "train_model.set_weights_for_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define attack used for adversarial training\n",
    "train_attack = PGD(model, eps=16, alpha=1, steps=15) # Hyperparameters from Section 5 https://arxiv.org/pdf/1812.03411.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "NUM_EPOCHS = 5\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(train_model.linear_layer.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "writer = SummaryWriter(LOG_PATH)\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    for i, (batch_images, batch_labels, _) in enumerate(tqdm(ori_loader)):\n",
    "        \n",
    "        X = train_attack(batch_images, batch_labels).to(DEVICE)\n",
    "        Y = batch_labels.to(DEVICE)\n",
    "\n",
    "        predictions = train_model(X)\n",
    "        cost = loss(predictions, Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1)%25 == 0:\n",
    "          print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], batch [{i+1}/{len(ori_loader)}], Loss: {cost.item()}')\n",
    "          train_model.set_weights_for_testing()\n",
    "\n",
    "          # Test accuracy for clean samples\n",
    "          correct_clean = 0\n",
    "          correct_adv = 0\n",
    "\n",
    "          for j, (imgs, labels, _) in enumerate(test_loader):\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                predictions = train_model(imgs)\n",
    "            correct_clean += torch.sum(torch.eq(predictions.argmax(1), labels))\n",
    "\n",
    "            adv_samples = train_attack(imgs, labels).cuda()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                predictions = train_model(adv_samples)\n",
    "            correct_adv += torch.sum(torch.eq(predictions.argmax(1), labels))\n",
    "\n",
    "          del imgs\n",
    "          del labels\n",
    "          del adv_samples\n",
    "\n",
    "          print(f\"Clean accuracy [{correct_clean}/{len(test_loader.dataset)}] = {correct_clean/len(test_loader.dataset)}\")\n",
    "          print(f\"Adversarial accuracy [{correct_adv}/{len(test_loader.dataset)}] = {correct_adv/len(test_loader.dataset)}\\n\")\n",
    "          train_model.set_weights_for_training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
