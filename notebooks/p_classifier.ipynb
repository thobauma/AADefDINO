{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install, Paths and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This extension reloads external Python files\n",
    "import os\n",
    "from pathlib import Path\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import sys\n",
    "from torch.utils.data import random_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# allow imports when running script from within project dir\n",
    "[sys.path.append(i) for i in ['.', '..']]\n",
    "\n",
    "# local\n",
    "from src.helpers.helpers import get_random_indexes, get_random_classes\n",
    "from src.model.dino_model import get_dino\n",
    "from src.model.train import *\n",
    "from src.model.data import *\n",
    "\n",
    "# seed\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "username = getpass.getuser()\n",
    "DATA_PATH = Path('/','cluster', 'scratch', 'thobauma', 'dl_data')\n",
    "MAX_PATH = Path('/','cluster', 'scratch', 'mmathys', 'dl_data')\n",
    "# Path for intermediate outputs\n",
    "# BASE_POSTHOC_PATH = Path(MAX_PATH, 'posthoc/')\n",
    "BASE_POSTHOC_PATH = Path(MAX_PATH, 'posthoc-subset/')\n",
    "\n",
    "# Original Dataset\n",
    "ORI_PATH = Path(DATA_PATH, 'ori_data/')\n",
    "CLASS_SUBSET_PATH = Path(ORI_PATH, 'class_subset.npy')\n",
    "\n",
    "TR_PATH = Path(ORI_PATH, 'train/')\n",
    "TR_ORI_LABEL_PATH = Path(TR_PATH,'correct_labels.txt')\n",
    "TR_ORI_IMAGES_PATH = Path(TR_PATH,'images')\n",
    "\n",
    "VAL_PATH = Path(ORI_PATH, 'validation/')\n",
    "VAL_ORI_LABEL_PATH = Path(VAL_PATH,'correct_labels.txt')\n",
    "VAL_ORI_IMAGES_PATH = Path(VAL_PATH,'images')\n",
    "\n",
    "# DAmageNet\n",
    "DN_PATH = Path(DATA_PATH, 'damageNet')\n",
    "DN_LABEL_PATH = Path(DN_PATH, 'val_damagenet.txt')\n",
    "DN_IMAGES_PATH = Path(DN_PATH, 'images')\n",
    "DN_POSTHOC_PATH = Path(BASE_POSTHOC_PATH, 'damagenet')\n",
    "DN_POSTHOC_LABEL_PATH = Path(DN_POSTHOC_PATH, 'labels.csv')\n",
    "\n",
    "# PGD\n",
    "TR_PGD_PATH = Path(MAX_PATH, 'adversarial_data/pgd_06/train')\n",
    "TR_PGD_LABEL_PATH = TR_ORI_LABEL_PATH\n",
    "TR_PGD_IMAGES_PATH = Path(TR_PGD_PATH, 'images')\n",
    "TR_PGD_POSTHOC_PATH = Path(BASE_POSTHOC_PATH, 'pgd/train/')\n",
    "TR_PGD_POSTHOC_LABEL_PATH = Path(TR_PGD_POSTHOC_PATH, 'labels.csv')\n",
    "\n",
    "VAL_PGD_PATH = Path(MAX_PATH, 'adversarial_data/pgd_06/validation')\n",
    "VAL_PGD_LABEL_PATH = VAL_ORI_LABEL_PATH\n",
    "VAL_PGD_IMAGES_PATH = Path(VAL_PGD_PATH, 'images')\n",
    "VAL_PGD_POSTHOC_PATH = Path(BASE_POSTHOC_PATH, 'pgd/validation/')\n",
    "VAL_PGD_POSTHOC_LABEL_PATH = Path(VAL_PGD_POSTHOC_PATH, 'labels.csv')\n",
    "\n",
    "# CW\n",
    "TR_CW_PATH = Path(MAX_PATH, 'adversarial_data/cw/train')\n",
    "TR_CW_LABEL_PATH = TR_ORI_LABEL_PATH\n",
    "TR_CW_IMAGES_PATH = Path(TR_CW_PATH, 'images')\n",
    "TR_CW_POSTHOC_PATH = Path(BASE_POSTHOC_PATH, 'cw/train/')\n",
    "TR_CW_POSTHOC_LABEL_PATH = Path(TR_CW_POSTHOC_PATH, 'labels.csv')\n",
    "\n",
    "VAL_CW_PATH = Path(MAX_PATH, 'adversarial_data/cw/validation')\n",
    "VAL_CW_LABEL_PATH = VAL_ORI_LABEL_PATH\n",
    "VAL_CW_IMAGES_PATH = Path(VAL_CW_PATH, 'images')\n",
    "VAL_CW_POSTHOC_PATH = Path(BASE_POSTHOC_PATH, 'cw/validation/')\n",
    "VAL_CW_POSTHOC_LABEL_PATH = Path(VAL_CW_POSTHOC_PATH, 'labels.csv')\n",
    "\n",
    "# FGSM\n",
    "TR_FGSM_PATH = Path(MAX_PATH, 'adversarial_data/fgsm_06/train')\n",
    "TR_FGSM_LABEL_PATH = TR_ORI_LABEL_PATH\n",
    "TR_FGSM_IMAGES_PATH = Path(TR_FGSM_PATH, 'images')\n",
    "TR_FGSM_POSTHOC_PATH = Path(BASE_POSTHOC_PATH, 'fgsm/train/')\n",
    "TR_FGSM_POSTHOC_LABEL_PATH = Path(TR_FGSM_POSTHOC_PATH, 'labels.csv')\n",
    "\n",
    "VAL_FGSM_PATH = Path(MAX_PATH, 'adversarial_data/fgsm_06/validation')\n",
    "VAL_FGSM_LABEL_PATH = VAL_ORI_LABEL_PATH\n",
    "VAL_FGSM_IMAGES_PATH = Path(VAL_FGSM_PATH, 'images')\n",
    "VAL_FGSM_POSTHOC_PATH = Path(BASE_POSTHOC_PATH, 'fgsm/validation/')\n",
    "VAL_FGSM_POSTHOC_LABEL_PATH = Path(VAL_FGSM_POSTHOC_PATH, 'labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If CLASS_SUBSET is specified, INDEX_SUBSET will be ignored. Set CLASS_SUBSET=None if you want to use indexes.\n",
    "# INDEX_SUBSET = get_random_indexes(number_of_images = 50000, n_samples=1000)\n",
    "# CLASS_SUBSET = get_random_classes(number_of_classes = 25, min_rand_class = 1, max_rand_class = 1001)\n",
    "\n",
    "\n",
    "CLASS_SUBSET = np.load(CLASS_SUBSET_PATH)\n",
    "CLASS_SUBSET = CLASS_SUBSET[:3]\n",
    "INDEX_SUBSET = None\n",
    "NUM_WORKERS= 0\n",
    "PIN_MEMORY=True\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_paths = {\n",
    "            'cw':{ \n",
    "                'b':{\n",
    "                    'train':{\n",
    "                        'label':TR_ORI_LABEL_PATH,\n",
    "                        'images':TR_CW_IMAGES_PATH\n",
    "                    },\n",
    "                    'val':\n",
    "                    {\n",
    "                        'label':VAL_ORI_LABEL_PATH,\n",
    "                        'images':VAL_CW_IMAGES_PATH\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            'ori':{\n",
    "                'b':{\n",
    "                    'train':{\n",
    "                        'label':TR_ORI_LABEL_PATH,\n",
    "                        'images':TR_ORI_IMAGES_PATH\n",
    "                    },\n",
    "                    'val':{\n",
    "                        'label':VAL_ORI_LABEL_PATH,\n",
    "                        'images':VAL_ORI_IMAGES_PATH\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            'dn':{\n",
    "                'b':{\n",
    "                    'train':{\n",
    "                        'label':TR_CW_PATH,\n",
    "                        'images':None\n",
    "                    },\n",
    "                    'val':\n",
    "                    {\n",
    "                        'label':VAL_ORI_LABEL_PATH,\n",
    "                        'images':DN_IMAGES_PATH\n",
    "                    }\n",
    "                 }\n",
    "            },\n",
    "            'fgsm_06':{\n",
    "                'b':{\n",
    "                    'train':{\n",
    "                        'label':TR_ORI_LABEL_PATH,\n",
    "                        'images':TR_FGSM_IMAGES_PATH\n",
    "                    },\n",
    "                    'val':\n",
    "                    {\n",
    "                        'label':VAL_ORI_LABEL_PATH,\n",
    "                        'images':VAL_FGSM_IMAGES_PATH\n",
    "                    }\n",
    "                 }\n",
    "            },\n",
    "            'pgd_06':{\n",
    "                'b':{\n",
    "                    'train':{\n",
    "                        'label':TR_ORI_LABEL_PATH,\n",
    "                        'images':TR_PGD_IMAGES_PATH\n",
    "                    },\n",
    "                    'val':\n",
    "                    {\n",
    "                        'label':VAL_ORI_LABEL_PATH,\n",
    "                        'images':VAL_PGD_IMAGES_PATH\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['cw', 'ori', 'pgd_06', 'fgsm_06']\n",
    "for ds in datasets:\n",
    "    ds_dict = datasets_paths[ds]\n",
    "    ds_dict['p'] = {\n",
    "        'train': { \n",
    "            'images': Path(BASE_POSTHOC_PATH, ds, 'train', 'images'),\n",
    "            'label': Path(BASE_POSTHOC_PATH, ds, 'train', 'labels.csv')\n",
    "        },\n",
    "        'val': { \n",
    "            'images': Path(BASE_POSTHOC_PATH, ds, 'val', 'images'),\n",
    "            'label': Path(BASE_POSTHOC_PATH, ds, 'val', 'labels.csv')\n",
    "        }\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'label': PosixPath('/cluster/scratch/thobauma/dl_data/ori_data/train/correct_labels.txt'),\n",
       "  'images': PosixPath('/cluster/scratch/mmathys/dl_data/adversarial_data/cw/train/images')},\n",
       " 'val': {'label': PosixPath('/cluster/scratch/thobauma/dl_data/ori_data/validation/correct_labels.txt'),\n",
       "  'images': PosixPath('/cluster/scratch/mmathys/dl_data/adversarial_data/cw/validation/images')}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_paths['cw']['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import DINO\n",
    "Official repo: https://github.com/facebookresearch/dino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please use the `--pretrained_weights` argument to indicate the path of the checkpoint to evaluate.\n",
      "Since no pretrained weights have been provided, we load the reference pretrained DINO weights.\n",
      "Model vit_small built.\n",
      "Embed dim 1536\n",
      "We load the reference pretrained linear weights.\n"
     ]
    }
   ],
   "source": [
    "model, linear_classifier = get_dino()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: /cluster/scratch/thobauma/dl_data/ori_data/train/images\n",
      "label: /cluster/scratch/thobauma/dl_data/ori_data/train/correct_labels.txt\n",
      "pred: /cluster/scratch/mmathys/dl_data/posthoc-subset/ori/train/labels.csv\n",
      "ori: train 5172\n",
      "saving predictions to: /cluster/scratch/mmathys/dl_data/posthoc-subset/ori/train/labels.csv\n",
      "Test:  [ 0/81]  eta: 0:01:59  loss: 0.499219 (0.499219)  acc1: 82.812500 (82.812500)  acc5: 100.000000 (100.000000)  time: 1.479434  data: 1.048032  max mem: 497\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 122] Disk quota exceeded: '/cluster/scratch/mmathys/dl_data/posthoc-subset/ori/train/images/n02114712_20140.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f711f78aade3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_WORKERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIN_MEMORY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'''{ds}: {tv} {len(data_set)}'''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mlogger_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madversarial_attack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_predictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/deeplearning/src/model/train.py\u001b[0m in \u001b[0;36mvalidate_network\u001b[0;34m(model, classifier, validation_loader, tensor_dir, adversarial_attack, n, avgpool, path_predictions)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;31m# save output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtensor_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                 \u001b[0msave_output_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deeplearning/src/model/train.py\u001b[0m in \u001b[0;36msave_output_batch\u001b[0;34m(batch_out, batch_names, output_dir)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;31m#        print('out',out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;31m#        print('path', out_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Disk quota exceeded: '/cluster/scratch/mmathys/dl_data/posthoc-subset/ori/train/images/n02114712_20140.pt'"
     ]
    }
   ],
   "source": [
    "logger_dict = {}\n",
    "for ds in ['ori', 'pgd_06', 'fgsm_06', 'cw']:\n",
    "    ds_b = datasets_paths[ds]['b']\n",
    "    ds_p = datasets_paths[ds]['p']\n",
    "    logger_dict[ds] = {}\n",
    "    transform = \n",
    "    for tv in ['train', 'val']:\n",
    "        print(f'''images: {ds_b[tv]['images']}\\nlabel: {ds_b[tv]['label']}\\npred: {ds_p[tv]['label']}''')\n",
    "        data_set = ImageDataset(ds_b[tv]['images'], ds_b[tv]['label'], ORIGINAL_TRANSFORM, class_subset=CLASS_SUBSET)\n",
    "        data_loader = DataLoader(data_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, shuffle=False)\n",
    "        print(f'''{ds}: {tv} {len(data_set)}''')\n",
    "        logger_dict[ds][tv] = validate_network(model, linear_classifier, data_loader, adversarial_attack=None, tensor_dir=ds_p[tv]['images'], path_predictions=ds_p[tv]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
