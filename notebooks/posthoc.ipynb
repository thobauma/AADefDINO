{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posthoc Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install, Paths and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This extension reloads external Python files\n",
    "import os\n",
    "from pathlib import Path\n",
    "import getpass\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# allow imports when running script from within project dir\n",
    "[sys.path.append(i) for i in ['.', '..']]\n",
    "\n",
    "# local\n",
    "from src.helpers.helpers import get_random_indexes, get_random_classes\n",
    "from src.model.dino_model import get_dino\n",
    "from src.model.data import create_loader, adv_dataset\n",
    "from src.model.eval import validate_network\n",
    "\n",
    "# seed\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "username = getpass.getuser()\n",
    "DATA_PATH = Path('/','cluster', 'scratch', 'thobauma', 'dl_data')\n",
    "\n",
    "DN_PATH = Path(DATA_PATH, 'damageNet')\n",
    "DN_LABEL_PATH = Path(DN_PATH, 'val_damagenet.txt')\n",
    "DN_IMAGES_PATH = Path(DN_PATH, 'images')\n",
    "\n",
    "ORI_PATH = Path(DATA_PATH, 'ori_data')\n",
    "ORI_LABEL_PATH = Path(ORI_PATH,'correct_labels.txt')\n",
    "ORI_IMAGES_PATH = Path(ORI_PATH,'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If CLASS_SUBSET is specified, INDEX_SUBSET will be ignored. Set CLASS_SUBSET=None if you want to use indexes.\n",
    "INDEX_SUBSET = get_random_indexes()\n",
    "CLASS_SUBSET = get_random_classes()\n",
    "INDEX_SUBSET = None\n",
    "CLASS_SUBSET = None\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!python $HOME/deeplearning/setup/collect_env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import DINO\n",
    "Official repo: https://github.com/facebookresearch/dino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please use the `--pretrained_weights` argument to indicate the path of the checkpoint to evaluate.\n",
      "Since no pretrained weights have been provided, we load the reference pretrained DINO weights.\n",
      "Model vit_small built.\n",
      "We load the reference pretrained linear weights.\n"
     ]
    }
   ],
   "source": [
    "model, linear_classifier = get_dino()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_loader = create_loader(ORI_IMAGES_PATH, ORI_LABEL_PATH, INDEX_SUBSET, CLASS_SUBSET, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_loader = create_loader(DN_IMAGES_PATH, DN_LABEL_PATH, INDEX_SUBSET, CLASS_SUBSET, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model linear classifier inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs a forward pass given a sample `inp` and a classifier.\n",
    "def generate_model_output(inp, n=4):\n",
    "    inp = inp.to(\"cuda\")\n",
    "    inp = inp.unsqueeze(dim=0)\n",
    "    intermediate_output = model.get_intermediate_layers(inp, n)\n",
    "    return torch.cat([x[:, 0] for x in intermediate_output], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuple 1000/1000"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# output first 5 tuples generated.\n",
    "samples = adv_dataset(ori_loader, dn_loader, model, linear_classifier)\n",
    "total=1000\n",
    "\n",
    "for i in range(total):\n",
    "  if i+1 % 10000 == 0:\n",
    "    drive.flush_and_unmount()\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "  num, org, adv = next(samples)\n",
    "  sys.stdout.write(f\"\\rtuple {i+1}/{total}\")\n",
    "  sys.stdout.flush()\n",
    "\n",
    "  # self attention\n",
    "  # add one dimension to input image (get_last_selfattention expects it)\n",
    "\n",
    "  org_out = generate_model_output(org)\n",
    "  adv_out = generate_model_output(adv)\n",
    "  \n",
    "  #torch.save(org_out, ORG_OUT_PATH + f\"{num}.pt\")\n",
    "  #torch.save(adv_out, ADV_OUT_PATH + f\"{num}.pt\")\n",
    "\n",
    "  # folders for org and adv, filename: {org, adv}/<original number>.pt (leave out prefix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
