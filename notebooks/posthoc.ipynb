{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posthoc Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install, Paths and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This extension reloads external Python files\n",
    "%load_ext autoreload\n",
    "import os\n",
    "from pathlib import Path\n",
    "import getpass\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# allow imports when running script from within project dir\n",
    "[sys.path.append(i) for i in ['.', '..']]\n",
    "\n",
    "# local\n",
    "from src.helpers.helpers import get_random_indexes, get_random_classes\n",
    "from src.model.dino_model import get_dino\n",
    "from src.model.data import create_loader, adv_dataset\n",
    "from src.model.eval import validate_network\n",
    "\n",
    "# seed\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "username = getpass.getuser()\n",
    "DATA_PATH = Path('/','cluster', 'scratch', 'thobauma', 'dl_data')\n",
    "\n",
    "DN_PATH = Path(DATA_PATH, 'damageNet')\n",
    "DN_LABEL_PATH = Path(DN_PATH, 'val_damagenet.txt')\n",
    "DN_IMAGES_PATH = Path(DN_PATH, 'images')\n",
    "\n",
    "ORI_PATH = Path(DATA_PATH, 'ori_data')\n",
    "ORI_LABEL_PATH = Path(ORI_PATH,'correct_labels.txt')\n",
    "ORI_IMAGES_PATH = Path(ORI_PATH,'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If CLASS_SUBSET is specified, INDEX_SUBSET will be ignored. Set CLASS_SUBSET=None if you want to use indexes.\n",
    "INDEX_SUBSET = get_random_indexes()\n",
    "CLASS_SUBSET = get_random_classes()\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!python $HOME/deeplearning/setup/collect_env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import DINO\n",
    "Official repo: https://github.com/facebookresearch/dino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please use the `--pretrained_weights` argument to indicate the path of the checkpoint to evaluate.\n",
      "Since no pretrained weights have been provided, we load the reference pretrained DINO weights.\n",
      "Model vit_small built.\n",
      "We load the reference pretrained linear weights.\n"
     ]
    }
   ],
   "source": [
    "model, linear_classifier = get_dino()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_loader = create_loader(ORI_IMAGES_PATH, ORI_LABEL_PATH, INDEX_SUBSET, CLASS_SUBSET, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_loader = create_loader(DN_IMAGES_PATH, DN_LABEL_PATH, INDEX_SUBSET, CLASS_SUBSET, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model linear classifier inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs a forward pass given a sample `inp` and a classifier.\n",
    "def generate_model_output(inp, n=4):\n",
    "    inp = inp.to(\"cuda\")\n",
    "    inp = inp.unsqueeze(dim=0)\n",
    "    print(inp.shape)\n",
    "    intermediate_output = model.get_intermediate_layers(inp, n)\n",
    "    return torch.cat([x[:, 0] for x in intermediate_output], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org_name: ILSVRC2012_val_00000007.JPEG, adv_name: ILSVRC2012_val_00000007.png\n",
      "tuple 1/1000torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "org_name: ILSVRC2012_val_00000011.JPEG, adv_name: ILSVRC2012_val_00000011.png\n",
      "org_name: ILSVRC2012_val_00000019.JPEG, adv_name: ILSVRC2012_val_00000019.png\n",
      "org_name: ILSVRC2012_val_00000021.JPEG, adv_name: ILSVRC2012_val_00000021.png\n",
      "tuple 2/1000torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "org_name: ILSVRC2012_val_00000093.JPEG, adv_name: ILSVRC2012_val_00000093.png\n",
      "tuple 3/1000torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "org_name: ILSVRC2012_val_00000098.JPEG, adv_name: ILSVRC2012_val_00000098.png\n",
      "tuple 4/1000torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "org_name: ILSVRC2012_val_00000104.JPEG, adv_name: ILSVRC2012_val_00000104.png\n",
      "org_name: ILSVRC2012_val_00000114.JPEG, adv_name: ILSVRC2012_val_00000114.png\n",
      "tuple 5/1000torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "org_name: ILSVRC2012_val_00000117.JPEG, adv_name: ILSVRC2012_val_00000148.png\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Numbers are not matching: org=ILSVRC2012_val_00000117.JPEG, adv=ILSVRC2012_val_00000148.png",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a2ff1f1f2300>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\rtuple {i+1}/{total}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AADefDINO/src/model/data.py\u001b[0m in \u001b[0;36madv_dataset\u001b[0;34m(org_loader, adv_loader, model, linear_classifier, n)\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0morg_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morg_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.JPEG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m       \u001b[0madv_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m       \u001b[0;32massert\u001b[0m \u001b[0morg_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0madv_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Numbers are not matching: org={org_name}, adv={adv_name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0morg_correct\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madv_correct\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Numbers are not matching: org=ILSVRC2012_val_00000117.JPEG, adv=ILSVRC2012_val_00000148.png"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# output first 5 tuples generated.\n",
    "samples = adv_dataset(ori_loader, dn_loader, model, linear_classifier)\n",
    "total=1000\n",
    "\n",
    "for i in range(total):\n",
    "  if i+1 % 10000 == 0:\n",
    "    drive.flush_and_unmount()\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "  num, org, adv = next(samples)\n",
    "  sys.stdout.write(f\"\\rtuple {i+1}/{total}\")\n",
    "  sys.stdout.flush()\n",
    "\n",
    "  # self attention\n",
    "  # add one dimension to input image (get_last_selfattention expects it)\n",
    "\n",
    "  org_out = generate_model_output(org)\n",
    "  adv_out = generate_model_output(adv)\n",
    "  \n",
    "  #torch.save(org_out, ORG_OUT_PATH + f\"{num}.pt\")\n",
    "  #torch.save(adv_out, ADV_OUT_PATH + f\"{num}.pt\")\n",
    "\n",
    "  # folders for org and adv, filename: {org, adv}/<original number>.pt (leave out prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
